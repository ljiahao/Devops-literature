# Security-Explainability
Explain GNN's applications in security domain with RL

## Explainability
- [ICML'17] [Axiomatic Attribution for Deep Networks](https://arxiv.org/pdf/1703.01365.pdf)
- [CCS'18] [LEMNA: Explaining Deep Learning based Security Applications](https://gangw.cs.illinois.edu/ccs18.pdf)
- [CCS'18] [Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations](https://dl.acm.org/doi/pdf/10.1145/3243734.3243834)
- [NeurIPS'18] [Explaining Deep Learning Models - A Bayesian Non-parametric Approach](https://arxiv.org/pdf/1811.03422.pdf)
- [NeurIPS'19] [GNNExplainer: Generating Explanations for Graph Neural Networks](https://arxiv.org/pdf/1903.03894.pdf)
- [NDSS'19] [Graph-based Security and Privacy Analytics via Collective Classification with Joint Weight Learning and Propagation](https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_11-1_Wang_paper.pdf)
- [NDSS'19] [NIC: Detecting Adversarial Samples with Neural Network Invariant Checking](https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_03A-4_Ma_paper.pdf)
- [ICLR'19] [Structured Adversarial Attack: Towards General Implementation and Better Interpretability](https://arxiv.org/pdf/1808.01664.pdf)
- [AAAI'19] [Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks](https://arxiv.org/pdf/1904.00605.pdf)
- [ICML'19] [Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Values Approximation](https://arxiv.org/pdf/1903.10992.pdf)
- [ARXIV'19] [Donâ€™t Paint It Black: White-Box Explanations for Deep Learning in Computer Security](https://intellisec.de/pubs/2019-paint.pdf)
- [EuroS&P'20] [Evaluating Explanation Methods for Deep Learning in Security](https://arxiv.org/pdf/1906.02108.pdf)
- [ESEC/FSE'20] [DENAS: Automated Rule Generation by Knowledge Extraction from Neural Networks](http://youngwei.com/pdf/DENAS.pdf)
- [ICML'20] [Fairwashing Explanations with Off-Manifold Detergent](https://arxiv.org/pdf/2007.09969.pdf)
- [NeurIPS'20] [PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks](https://arxiv.org/pdf/2010.05788.pdf)
- [NeurIPS'20] [Parameterized Explainer for Graph Neural Network](https://arxiv.org/pdf/2011.04573.pdf)
- [CVPR'20] [Towards Global Explanations of Convolutional Neural Networks With Concept Attribution](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_Towards_Global_Explanations_of_Convolutional_Neural_Networks_With_Concept_Attribution_CVPR_2020_paper.pdf)
- [KDD'20] [XGNN: Towards Model-Level Explanations of Graph Neural Networks](https://arxiv.org/pdf/2006.02587.pdf)
- [ICLR'21] [Evaluations and Methods for Explanation through Robustness Analysis](https://arxiv.org/pdf/2006.00442.pdf)
- [Security'21] [CADE: Detecting and Explaining Concept Drift Samples for Security Applications](https://www.usenix.org/system/files/sec21summer_yang.pdf)
- [KDD'21] [Mutual Information Preserving Back-propagation: Learn to Invert for Faithful Attribution](https://arxiv.org/pdf/2104.06629.pdf)
- [ICML'21] [Generative Causal Explanations for Graph Neural Networks](https://arxiv.org/pdf/2104.06643.pdf)
- [ICML'21] [On Explainability of Graph Neural Networks via Subgraph Explorations](https://arxiv.org/pdf/2102.05152.pdf)
- [NeurIPS'21] [Towards Multi-Grained Explainability for Graph Neural Networks](http://staff.ustc.edu.cn/~hexn/papers/nips21-explain-gnn.pdf)
- [NeurIPS'21] [Reinforcement Learning Enhanced Explainer for Graph Neural Networks](https://proceedings.neurips.cc/paper/2021/file/be26abe76fb5c8a4921cf9d3e865b454-Paper.pdf)
- [NeurIPS'21] [Robust Counterfactual Explanations on Graph Neural Networks](https://arxiv.org/pdf/2107.04086.pdf)
- [NeurIPS'21] [Learning Theory Can (Sometimes) Explain Generalisation in Graph Neural Networks](https://proceedings.neurips.cc/paper/2021/file/e34376937c784505d9b4fcd980c2f1ce-Paper.pdf)
- [ICLR'22] [Discovering Invariant Rationales For Graph Neural Networks](https://openreview.net/pdf?id=hGXij5rfiHw)
- [ICLR'22] [Handling Distribution Shifts on Graphs: An Invariance Perspective](https://openreview.net/pdf?id=FQOC5u-1egI)
- [TPAMI'22] [Reinforced Causal Explainer for Graph Neural Networks](https://arxiv.org/pdf/2204.11028.pdf)
- [DSN'22] [CFGExplainer: Explaining Graph Neural Network-Based Malware Classification from Control Flow Graphs](http://www.cs.binghamton.edu/~ghyan/papers/dsn22.pdf)
- [WWW'22] [Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/pdf/2202.08816.pdf)
- [ICML'22] [Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism](https://arxiv.org/pdf/2201.12987.pdf)

## Security Applications
### Malware Detection
- [NDSS'17] [MaMaDroid: Detecting Android Malware by Building Markov Chains of Behavioral Models](https://www.ndss-symposium.org/wp-content/uploads/2017/09/ndss2017_03B-3_Mariconti_paper.pdf)
- [ASE'19] [MalScan: Fast Market-Wide Mobile Malware Scanning by Social-Network Centrality Analysis](https://wu-yueming.github.io/Files/ASE2019_MalScan.pdf)
- [CCS'21] [Structural Attack against Graph Based Android Malware Detection](https://www4.comp.polyu.edu.hk/~csxluo/HRAT.pdf)

### Binary Similarity
- [CCS'17] [Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection](https://acmccs.github.io/papers/p363-xuAemb.pdf)
- [Security'22] [How Machine Learning Is Solving the Binary Function Similarity Problem](https://www.usenix.org/system/files/sec22fall_marcelli.pdf)