# Security-Explainability

## Explainability
- [ICML'17] [Axiomatic Attribution for Deep Networks](https://arxiv.org/pdf/1703.01365.pdf)
- [CCS'18] [LEMNA: Explaining Deep Learning based Security Applications](https://gangw.cs.illinois.edu/ccs18.pdf)
- [CCS'18] [Property Inference Attacks on Fully Connected Neural Networks using Permutation Invariant Representations](https://dl.acm.org/doi/pdf/10.1145/3243734.3243834)
- [NeurIPS'18] [Explaining Deep Learning Models - A Bayesian Non-parametric Approach](https://arxiv.org/pdf/1811.03422.pdf)
- [NeurIPS'19] [GNNExplainer: Generating Explanations for Graph Neural Networks](https://arxiv.org/pdf/1903.03894.pdf)
- [NDSS'19] [Graph-based Security and Privacy Analytics via Collective Classification with Joint Weight Learning and Propagation](https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_11-1_Wang_paper.pdf)
- [NDSS'19] [NIC: Detecting Adversarial Samples with Neural Network Invariant Checking](https://www.ndss-symposium.org/wp-content/uploads/2019/02/ndss2019_03A-4_Ma_paper.pdf)
- [ICLR'19] [Structured Adversarial Attack: Towards General Implementation and Better Interpretability](https://arxiv.org/pdf/1808.01664.pdf)
- [AAAI'19] [Relative Attributing Propagation: Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks](https://arxiv.org/pdf/1904.00605.pdf)
- [ICML'19] [Explaining Deep Neural Networks with a Polynomial Time Algorithm for Shapley Values Approximation](https://arxiv.org/pdf/1903.10992.pdf)
- [ARXIV'19] [Donâ€™t Paint It Black: White-Box Explanations for Deep Learning in Computer Security](https://intellisec.de/pubs/2019-paint.pdf)
- [EuroS&P'20] [Evaluating Explanation Methods for Deep Learning in Security](https://arxiv.org/pdf/1906.02108.pdf)
- [ESEC/FSE'20] [DENAS: Automated Rule Generation by Knowledge Extraction from Neural Networks](http://youngwei.com/pdf/DENAS.pdf)
- [ICML'20] [Fairwashing Explanations with Off-Manifold Detergent](https://arxiv.org/pdf/2007.09969.pdf)
- [NeurIPS'20] [PGM-Explainer: Probabilistic Graphical Model Explanations for Graph Neural Networks](https://arxiv.org/pdf/2010.05788.pdf)
- [NeurIPS'20] [Parameterized Explainer for Graph Neural Network](https://arxiv.org/pdf/2011.04573.pdf)
- [CVPR'20] [Towards Global Explanations of Convolutional Neural Networks With Concept Attribution](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_Towards_Global_Explanations_of_Convolutional_Neural_Networks_With_Concept_Attribution_CVPR_2020_paper.pdf)
- [KDD'20] [XGNN: Towards Model-Level Explanations of Graph Neural Networks](https://arxiv.org/pdf/2006.02587.pdf)
- [ICLR'21] [Evaluations and Methods for Explanation through Robustness Analysis](https://arxiv.org/pdf/2006.00442.pdf)
- [Security'21] [CADE: Detecting and Explaining Concept Drift Samples for Security Applications](https://www.usenix.org/system/files/sec21summer_yang.pdf)
- [KDD'21] [Mutual Information Preserving Back-propagation: Learn to Invert for Faithful Attribution](https://arxiv.org/pdf/2104.06629.pdf)
- [ICML'21] [Generative Causal Explanations for Graph Neural Networks](https://arxiv.org/pdf/2104.06643.pdf)
- [ICML'21] [On Explainability of Graph Neural Networks via Subgraph Explorations](https://arxiv.org/pdf/2102.05152.pdf)
- [NeurIPS'21] [Towards Multi-Grained Explainability for Graph Neural Networks](http://staff.ustc.edu.cn/~hexn/papers/nips21-explain-gnn.pdf)
- [NeurIPS'21] [Reinforcement Learning Enhanced Explainer for Graph Neural Networks](https://proceedings.neurips.cc/paper/2021/file/be26abe76fb5c8a4921cf9d3e865b454-Paper.pdf)
- [NeurIPS'21] [Robust Counterfactual Explanations on Graph Neural Networks](https://arxiv.org/pdf/2107.04086.pdf)
- [NeurIPS'21] [Learning Theory Can (Sometimes) Explain Generalisation in Graph Neural Networks](https://proceedings.neurips.cc/paper/2021/file/e34376937c784505d9b4fcd980c2f1ce-Paper.pdf)
- [ICLR'22] [Discovering Invariant Rationales For Graph Neural Networks](https://openreview.net/pdf?id=hGXij5rfiHw)
- [ICLR'22] [Handling Distribution Shifts on Graphs: An Invariance Perspective](https://openreview.net/pdf?id=FQOC5u-1egI)
- [TPAMI'22] [Reinforced Causal Explainer for Graph Neural Networks](https://arxiv.org/pdf/2204.11028.pdf)
- [DSN'22] [CFGExplainer: Explaining Graph Neural Network-Based Malware Classification from Control Flow Graphs](http://www.cs.binghamton.edu/~ghyan/papers/dsn22.pdf)
- [WWW'22] [Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/pdf/2202.08816.pdf)
- [ICML'22] [Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism](https://arxiv.org/pdf/2201.12987.pdf)

## Security Applications
### Malware Detection
- [NDSS'17] [MaMaDroid: Detecting Android Malware by Building Markov Chains of Behavioral Models](https://www.ndss-symposium.org/wp-content/uploads/2017/09/ndss2017_03B-3_Mariconti_paper.pdf)
- [ASE'19] [MalScan: Fast Market-Wide Mobile Malware Scanning by Social-Network Centrality Analysis](https://wu-yueming.github.io/Files/ASE2019_MalScan.pdf)
- [CCS'21] [Structural Attack against Graph Based Android Malware Detection](https://www4.comp.polyu.edu.hk/~csxluo/HRAT.pdf)
- [INFOCOM'22] [MalGraph: Hierarchical Graph Neural Networks for Robust Windows Malware Detection](https://nesa.zju.edu.cn/download/lx_pdf_malgraph.pdf)
- [TDSC'22] [MsDroid: Identifying Malicious Snippets for Android Malware Detection](https://ieeexplore.ieee.org/document/9762803)

### Binary Similarity
- [CCS'17] [Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection](https://acmccs.github.io/papers/p363-xuAemb.pdf)
- [ICML'19] [Graph Matching Networks for Learning the Similarity of Graph Structured Objects](http://proceedings.mlr.press/v97/li19d/li19d.pdf)
- [Security'22] [How Machine Learning Is Solving the Binary Function Similarity Problem](https://www.usenix.org/system/files/sec22fall_marcelli.pdf)

## Concept Drift
### Survey
- [CSUR'14] [A survey on concept drift adaptation](https://www.win.tue.nl/~mpechen/publications/pubs/Gama_ACMCS_AdaptationCD_accepted.pdf)

### Detection
- [ICML'14] [Concept drift detection through resampling](http://proceedings.mlr.press/v32/harel14.pdf)
- [KDD'16] [Fast Unsupervised Online Drift Detection Using Incremental Kolmogorov-Smirnov Test](https://www.kdd.org/kdd2016/papers/files/rpp0427-dos-reisA.pdf)
- [ICLR'17] [A Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks](https://arxiv.org/pdf/1610.02136.pdf)
- [Security'17] [Transcend: Detecting Concept Drift in Malware Classification Models](https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-jordaney.pdf)
- [Security'21] [CADE: Detecting and Explaining Concept Drift Samples for Security Applications](http://www.personal.psu.edu/wzg13/publications/usenix21_2.pdf)
- [ASIA CCS'22] [EVOLIoT: A Self-Supervised Contrastive Learning Framework for Detecting and Characterizing Evolving IoT Malware Variants](https://dl.acm.org/doi/pdf/10.1145/3488932.3517393)

### Prevention
- [Security'19] [TESSERACT: Eliminating Experimental Bias in Malware Classification across Space and Time](https://www.usenix.org/system/files/sec19-pendlebury.pdf)
- [SP'20] [Throwing Darts in the Dark? Detecting Bots with Limited Data using Neural Data Augmentation](https://gangw.cs.illinois.edu/sp20-odds.pdf)
- [CCS'20] [Enhancing State-of-the-art Classifiers with API Semantics to Detect Evolved Android Malware](https://dl.acm.org/doi/pdf/10.1145/3372297.3417291)